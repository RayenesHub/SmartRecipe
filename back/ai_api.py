# ai_api.py
# ------------------------------------------------------------------
# Module d'acc√®s aux services IA :
# - Texte : via Ollama (local, gratuit)
# - Image : via Hugging Face (FLUX.1-dev)
# ------------------------------------------------------------------

import subprocess            # pour ex√©cuter la commande 'ollama run'
import os                    # pour lire les variables d'environnement (.env)
import requests              # pour appeler l'API Hugging Face
import base64                # pour encoder l'image en base64 (utile c√¥t√© front)
from dotenv import load_dotenv  # pour charger le fichier .env

# Charge les variables d'environnement depuis .env (HUGGINGFACE_API_TOKEN)
load_dotenv()

#la cl√© Hugging Face 
HF_API_KEY = os.getenv("HUGGINGFACE_API_TOKEN")

# Choix du mod√®le image
HF_MODEL = "black-forest-labs/FLUX.1-dev"

# Endpoint de l'API Inference de Hugging Face
API_URL = f"https://api-inference.huggingface.co/models/{HF_MODEL}"

# En-t√™tes HTTP incluant la cl√© d'authentification
headers = {"Authorization": f"Bearer {HF_API_KEY}"}


def generate_image_from_text(prompt):
    """
    G√©n√®re une image depuis Hugging Face (FLUX.1-dev) et renvoie en base64.
    """
    print(f"üé® G√©n√©ration d'image pour : {prompt}")
    payload = {"inputs": prompt}

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
        if response.status_code != 200:
            print("‚ö†Ô∏è Erreur HuggingFace:", response.text)
            return {"error": f"HuggingFace {response.status_code}: {response.text}"}

        # V√©rifie le type MIME pour s'assurer qu'on re√ßoit bien une image
        content_type = response.headers.get("Content-Type", "")
        if "image" not in content_type:
            print("‚ö†Ô∏è R√©ponse inattendue :", response.text[:300])
            return {"error": "R√©ponse non-image renvoy√©e par Hugging Face."}

        # Encode l'image en base64
        import base64
        image_b64 = base64.b64encode(response.content).decode("utf-8")
        return {"image_b64": f"data:image/png;base64,{image_b64}"}

    except requests.exceptions.RequestException as e:
        return {"error": f"Erreur de connexion Hugging Face: {str(e)}"}


def generate_text(prompt: str) -> str:
    """
    G√©n√®re du texte localement via Ollama (UTF-8).
    Sur Windows, 'text=True' peut d√©coder en cp1252 ‚Üí forcer encoding='utf-8'.
    """
    try:
        result = subprocess.run(
            ["ollama", "run", "mistral", prompt],   # ou "llama3"
            capture_output=True,                    # capture stdout/stderr
            text=True,                              # retourne des str (pas bytes)
            encoding="utf-8",                       # üî¥ forcer UTF-8 (cl√© du fix)
            errors="replace",                       # remplace tout char ill√©gal (s√©curit√©)
            timeout=120
        )

        # stdout est maintenant correctement d√©cod√© en UTF-8
        return result.stdout.strip()

    except subprocess.TimeoutExpired:
        return "Erreur : Ollama a mis trop de temps √† r√©pondre."
    except Exception as e:
        return f"Erreur Ollama : {str(e)}"
